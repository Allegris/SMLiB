---
output:
  html_document:
        theme: readable
editor_options: 
  chunk_output_type: console
---

```{r}

library(glmnet)
library(tidyverse)

df <- read_rds(file = "datasets/ALS_data_regression/ALS_progression_rate.1822x370.rds")  %>% tbl_df()

df <- df %>% rename(response = dFRS)

head(df)

```

# Split into training and prediction set

```{r}

set.seed(0)

data_train    <- df %>% filter(!is.na(response))
data_train    <- na.omit(data_train)
data_predict  <- df %>% filter(is.na(response))                              

dim(data_predict)
dim(data_train)

```

# Example of simple prediction using the mean value

```{r}

# RIDGE REGRESSION

# Always make the same split
set.seed(0)

x <- model.matrix(response ~ ., data_train)[, -1]
y <- data_train$response
# Randomly sample a subset of numbers between 1 and nrow(x)
# We use 80% for training and 20% for evaluation
train <- sample(1 : nrow(x), nrow(x) / 5)
test <- (-train)

# Train fit
fit <- glmnet(x[train, ], y[train], alpha = 0)

# Find best lambda using CV
cv_lambda <- cv.glmnet(x[train, ], y[train], alpha = 0)
#plot(cv_lambda)
best_lambda <- cv_lambda$lambda.min

# Test MSE
predicted <- predict(fit, s = best_lambda, newx = x[test, ])

# We compare with the observed values and calculate RMSE
observed  <- y[test]
mse       <- mean((observed-predicted)^2)
(rmse     <- sqrt(mse)) # 0.5422445

test_rmse <- rmse # Our guess on the general rmse of the model (very unprecise!)

# Fit model on all our data using found best lambda
fit <- glmnet(x, y, alpha = 0)
predicted <- predict(fit, s = best_lambda, newx = x)

```

```{r}

# Elastic net with alpha = 0.5 (combination of ridge and lasso)

# Always make the same split
set.seed(0)

x <- model.matrix(response ~ ., data_train)[, -1]
y <- data_train$response
# Randomly sample a subset of numbers between 1 and nrow(x)
# We use 80% for training and 20% for evaluation
train <- sample(1 : nrow(x), nrow(x) / 5)
test <- (-train)

# Train fit
fit <- glmnet(x[train, ], y[train], alpha = 0.5)

# Find best lambda using CV
cv_lambda <- cv.glmnet(x[train, ], y[train], alpha = 0.5)
#plot(cv_lambda)
best_lambda <- cv_lambda$lambda.min

# Predict
predicted <- predict(fit, s = best_lambda, newx = x[test, ])

# We compare with the observed values and calculate RMSE
observed  <- y[test]
mse       <- mean((observed-predicted)^2)
(rmse     <- sqrt(mse)) # 0.5261383

test_rmse <- rmse # Our guess on the general rmse of the model (very unprecise!)

# Fit model on all our data using found best lambda
fit <- glmnet(x, y, alpha = 1)
predicted <- predict(fit, s = best_lambda, newx = x)


```


```{r}

# THE LASSO - final model round 2

# Always make the same split
set.seed(0)

x <- model.matrix(response ~ ., data_train)[, -1]
y <- data_train$response
# Randomly sample a subset of numbers between 1 and nrow(x)
# We use 80% for training and 20% for evaluation
train <- sample(1 : nrow(x), nrow(x) / 5)
test <- (-train)

# Train fit
fit <- glmnet(x[train, ], y[train], alpha = 1)

# Find best lambda using CV
cv_lambda <- cv.glmnet(x[train, ], y[train], alpha = 1)
#plot(cv_lambda)
best_lambda <- cv_lambda$lambda.min

# Predict
predicted <- predict(fit, s = best_lambda, newx = x[test, ])

# We compare with the observed values and calculate RMSE
observed  <- y[test]
mse       <- mean((observed-predicted)^2)
(rmse     <- sqrt(mse)) # 0.5263135

test_rmse <- rmse # Our guess on the general rmse of the model (very unprecise!)

# Fit model on all our data using found best lambda
fit <- glmnet(x, y, alpha = 1)
predicted <- predict(fit, s = best_lambda, newx = x)


```


# Plot of testfold observed and predicted values and residuals
 

```{r}

pd  <- tibble(observed, predicted) %>% 
  mutate(residual = observed - predicted)


ggplot(pd, aes(x=observed, y=predicted)) + 
  geom_point() +
  theme_classic() +
  NULL


ggplot(pd, aes(x=observed, y=residual)) + 
  geom_point() +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme_classic() +
  NULL

rm(pd)

```

# Predict the real unknown data

First we fit the model to all of our known data

Then we predict on the unknown data

The predictions must have the following column and the row order must be the same as the original!

* predicted (the predicted value)

```{r}

#fit <-  lm(formula  = response ~ 1, data = data_train)

#predicted <- predict(object=fit, newdata = data_predict, type = "response")

submission <- tibble(predicted)

head(submission)

```

# Submitting your answer

The following code will give us

* your chosen team name
* the name of the people on the team
* your estimated RMSE (from train/test or CV or similar)
* your predictions

Please edit the values below .

The filename of the output will be automated als_progression.TEAMNAME.rds

Please - do not use space or funny letters in your team name.

```{r}

team_name        <- "team_NA"
team_people      <- c("Nicklas", "Astrid")
team_error_rate  <- test_rmse
team_predictions <- submission # This should be a tibble with a column called "predicted"

#
# Always run this code
# If it fails you have done something wrong!
#
# Extract the columns needed
team_predictions <- team_predictions %>% select(predicted)

# Save all the stuff in one object
write_rds(x = list(team_name, team_people, team_error_rate, team_predictions), 
          file = paste("als_progression.", team_name, ".rds", sep=""))

```

# Checking format of all saved objects

```{r}

files   <- Sys.glob("als_progression.*.rds")
results <- tibble(filename = files, team_name=NA, team_people=NA, team_rmse=NA,n=NA, mean=NA)

for (i in 1:nrow(results)) {
  x <- read_rds(file = as.character(results$filename[i]))
  results$team_name[i]        <- x[[1]]
  results$team_people[i]      <- paste(x[[2]], collapse=",", sep=" ")
  results$team_rmse[i]        <- x[[3]]
  y                           <- x[[4]]
  results$n                   <- nrow(y)
  results$mean                <- mean(y$predicted, na.rm = T)
  results$submission[i]       <- list(x[[4]])
}

rm(x,y)

results %>% select(-filename)

results$submission[[1]]

```

# Upload your rds file!


